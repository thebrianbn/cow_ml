{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn import svm, metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_rows = 4000\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in datasets, drop null rows\n",
    "\n",
    "xls = pd.ExcelFile('rottman.xlsx')\n",
    "blood = pd.read_excel(xls, 'Blood')\n",
    "ammonia = pd.read_excel(xls, 'Ammonia')\n",
    "vfa = pd.read_excel(xls, 'VFA')\n",
    "milk_FA = pd.read_excel(xls,'MILK FA Profile')\n",
    "\n",
    "xls2 = pd.ExcelFile('fcr.xlsx')\n",
    "fcr = pd.read_excel(xls2,'FCR')\n",
    "\n",
    "blood = blood.dropna()\n",
    "ammonia = ammonia.dropna()\n",
    "vfa = vfa.dropna()\n",
    "milk_FA = milk_FA.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "\n",
    "We decided to convert the time values we were given, military time, to \"number of hours after midnight\", allowing our data to be evenly spaced out.  We also were given many potential output values to look at the the FCR dataset, namely the composition of the food eaten.  For this week, we decided to solely investigate the raw kilograms of food eaten, potentially looking into the other values in later weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_output = fcr[[\"per\",\"Cow\",\"miltarytime\",\"kgPerH_asfed\"]]\n",
    "raw_output.rename(columns={'per':'Period', 'miltarytime':'Time','kgPerH_asfed':'kg_consumed'},inplace=True)\n",
    "#convert from military time to number of hours in float\n",
    "def helper(row):\n",
    "    if str(row.Time)[-4:] == '30.0':\n",
    "        return float((str(row.Time)[:-4] + '50'))\n",
    "    return row.Time\n",
    "\n",
    "raw_output.Time = raw_output.apply(helper,axis=1)\n",
    "raw_output.Time = raw_output.Time / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end goal with this dataset is predict a cow's intake time based on its blood and plasma data.  To this end, we decided to create two versions of our initial model.  Both would take as inputs the cow's ammonia content, relevant blood information, and total volatile fatty acids as inputs.  The second model would also consider whether the cow had been milked in the past 2 hours, the logic here being that a cow recently milked would be hungrier.  Cows are milked at 0700 and 1700 every day, but we only considered 1700 to be relevant, since cows are fed at 0900 every days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfa.Period = vfa.Period.apply(lambda x: x[1:])\n",
    "ammonia.Time = ammonia.Time.astype(float)\n",
    "blood.Time =  blood.Time.astype(float)\n",
    "vfa.Time = vfa.Time.astype(float)\n",
    "ammonia.Period = ammonia.Period.astype(int)\n",
    "blood.Period = blood.Period.astype(int)\n",
    "vfa.Period = vfa.Period.astype(int)\n",
    "ammonia.Cow = ammonia.Cow.astype(int)\n",
    "blood.Cow = blood.Cow.astype(int)\n",
    "vfa.Cow = vfa.Cow.astype(int)\n",
    "\n",
    "inputs5 = pd.merge(blood,ammonia,how='left', left_on=['Cow','Period','Time'],right_on=['Cow','Period','Time'])\n",
    "inputs5 = inputs5.drop(columns = [\"Sequence_x\",\"Treatment_x\"])\n",
    "inputs5.rename(columns = {'Sequence_y':'Sequence','Treatment_y':'Treatment'}, inplace = True)\n",
    "\n",
    "vfa = vfa[[\"Cow\",\"Period\",\"Time\",\"Total VFA\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.merge(inputs5,vfa,how=\"left\",left_on=['Cow','Period','Time'],right_on=['Cow','Period','Time'])\n",
    "inputs.Time = (inputs.Time / 100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Period   Cow  Time  kg_consumed\n",
      "0       1  1157  10.0       14.618\n",
      "1       1  1157  10.5        0.750\n",
      "2       1  1157  11.0        0.724\n",
      "3       1  1157  11.5       -0.856\n",
      "4       1  1157  12.0        5.894\n",
      "5       1  1157  12.5        8.070\n",
      "6       1  1157  13.0        5.346\n",
      "7       1  1157  13.5        1.166\n",
      "8       1  1157  14.0        1.750\n",
      "9       1  1157  14.5        5.916\n",
      "    Cow  Period  Time    BUN Glucose    NEFA Insulin Sequence Treatment  \\\n",
      "0  1157       1     3   9.77   62.67  108.88  26.372        C       CLH   \n",
      "1  1157       1     6   9.99    66.3  143.68   9.548        C       CLH   \n",
      "2  1157       1     9  12.31   66.29  131.14   6.717        C       CLH   \n",
      "3  1157       1    12  10.67   60.92  113.67  19.339        C       CLH   \n",
      "4  1157       1    15   9.78   59.73  132.69   17.18        C       CLH   \n",
      "5  1157       1    18  10.47   62.55  137.15   50.87        C       CLH   \n",
      "6  1157       1    21   9.85   65.35  153.08  17.893        C       CLH   \n",
      "7  1157       1    24   8.45   57.97  112.27  19.455        C       CLH   \n",
      "8  1157       2     3   6.88   62.56  109.70   19.93        L       CLH   \n",
      "9  1157       2     6   7.12   68.47  110.09   22.83        L       CLH   \n",
      "\n",
      "   Ammonia Total VFA  \n",
      "0  4.58528   113.621  \n",
      "1  4.56729   98.7111  \n",
      "2  10.0758   100.891  \n",
      "3  6.48879   123.263  \n",
      "4   7.7179   102.767  \n",
      "5  8.78011   119.862  \n",
      "6   6.8811   109.895  \n",
      "7  5.61599   127.741  \n",
      "8  6.23258   119.321  \n",
      "9  5.56583   104.754  \n"
     ]
    }
   ],
   "source": [
    "print(raw_output.head(10))\n",
    "print(inputs.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immediately ran into a problem - we had input data for every three hours, and our output data ran every half an hour.  We needed to fill in the gaps in our input data.  To do so, we assumed a linear relationship between hours 3 and 6 for every parameter.  For example, for cow 1157 on period 1, the value for BUN increases from 9.77 to 9.99.  So, for hour 3.5, our computed value for BUN is 9.77 + (9.99 - 9.77)/6 = 9.806667.  A naive assumption, for sure, but better than duplicating data or eliminating those rows entirely, as that would leave us with very little data to work with.\n",
    "\n",
    "We did this for every hour gap and every parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Filling in time gaps in our input data, assuming a linear relationship\n",
    "\n",
    "#duplicating rows\n",
    "inputs = inputs.reindex(np.repeat(inputs.index.values, 6), method='ffill')\n",
    "inputs = inputs.reset_index()\n",
    "inputs = inputs.drop(columns=[\"index\"])\n",
    "\n",
    "#removing some value that just have '.'\n",
    "for col in [\"Time\",\"BUN\",\"Glucose\",\"NEFA\",\"Insulin\",\"Ammonia\",\"Total VFA\"]:\n",
    "    inputs[col] = pd.to_numeric(inputs[col], errors = 'coerce') \n",
    "inputs = inputs.dropna()\n",
    "\n",
    "\n",
    "#changing the time of duplicated rows\n",
    "def helper(row):\n",
    "    if row.Time == 24.0:\n",
    "        row.Time = 0.0\n",
    "    return row.Time + ((row.name % 6) / 2.0)\n",
    "\n",
    "\n",
    "inputs.Time = inputs.apply(helper,axis=1)\n",
    "copy1 = inputs\n",
    "\n",
    "#linear assumption for values\n",
    "for index, row in inputs.iterrows():\n",
    "    index_next = index + 6 - (index % 6)\n",
    "    index_prior = index_next - 6\n",
    "    index_mult = index % 6\n",
    "    for col in [\"BUN\",\"Glucose\",\"NEFA\",\"Insulin\",\"Ammonia\",\"Total VFA\"]:\n",
    "        try:\n",
    "            diff = (inputs.iloc[index_next][col] - inputs.iloc[index_prior][col]) / 6\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "        inputs.at[index,col] = row[col] + diff*index_mult\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second version of the model, we needed to add a boolean that would indicate if the cow has given milk in the past 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_milk(row):\n",
    "    if row.Time in [17.0,17.5,18.0, 18.5, 19.0]:\n",
    "        return 1\n",
    "    return 0\n",
    "inputs[\"milked\"] = inputs.apply(helper_milk,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging datasets\n",
    "whole = pd.merge(inputs,raw_output,how='left',left_on = ['Cow','Period','Time'],right_on=['Cow','Period','Time'])\n",
    "\n",
    "#removing some values that just have '.'\n",
    "for col in [\"Time\",\"BUN\",\"Glucose\",\"NEFA\",\"Insulin\",\"Ammonia\",'Total VFA','kg_consumed']:\n",
    "    whole[col] = pd.to_numeric(whole[col], errors = 'coerce') \n",
    "\n",
    "whole = whole.dropna()\n",
    "\n",
    "##data is now ready\n",
    "whole = whole[[\"Time\",\"BUN\",\"Glucose\",\"NEFA\",\"Insulin\",'Total VFA','milked',\"kg_consumed\"]]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(whole[[\"Time\",\"BUN\",\"Glucose\",\"NEFA\",\"Insulin\",'Total VFA']], whole[\"kg_consumed\"], test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09552940498804563\n",
      "0.6146519405591608\n"
     ]
    }
   ],
   "source": [
    "#lasso regression for Model 1\n",
    "lasso = Lasso(alpha=0)\n",
    "lasso.fit(X_train, y_train)\n",
    "print(lasso.score(X_test, y_test))\n",
    "\n",
    "#Random Forest for Model 1\n",
    "randomf = RandomForestRegressor(n_estimators = 1000)\n",
    "\n",
    "randomf.fit(X_train,y_train)\n",
    "print(randomf.score(X_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08969391425207385\n",
      "0.5124461094912223\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(whole[[\"Time\",\"BUN\",\"Glucose\",\"NEFA\",\"Insulin\",'Total VFA','milked']], whole[\"kg_consumed\"], test_size=0.3)\n",
    "\n",
    "#lasso regression for Model 2\n",
    "\n",
    "lasso = Lasso(alpha=0)\n",
    "lasso.fit(X_train, y_train)\n",
    "print(lasso.score(X_test, y_test))\n",
    "\n",
    "#Random Forest for Model 2\n",
    "\n",
    "randomf = RandomForestRegressor(n_estimators = 1000)\n",
    "\n",
    "randomf.fit(X_train,y_train)\n",
    "print(randomf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our models are really, really bad.  We thought on it and realized that we weren't exactly answering the question at hand.  Our model aims to predict the number of kilograms of feed a cow eats at a specific time of the day.  The original question, as posed in Dr. Harvatine's lecture, was more along the lines of \"At what times do cows eat?\"  We figured we could extrapolate the time eaten from the kilograms eaten every hour, but with our innacuracy that won't be possible.  From this point, we decided to let the regression sit for a while and shift our focus to a binary case - given a certain time, is the cow eating or not?\n",
    "\n",
    "This problem is multifold.  We first need to determine a threshold for if the cow is eating or not.  Most of our values were above 0, but many were trivial, so we decided that all entries with <1 kg of food eaten would be considered the cow not eating, as they could be chalked up to error, food falling off the measuring device, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5633333333333334\n"
     ]
    }
   ],
   "source": [
    "whole[\"is_eating\"] = whole[\"kg_consumed\"] > 1\n",
    "print(np.mean(whole.is_eating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6916666666666667\n"
     ]
    }
   ],
   "source": [
    "##SVM\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(whole[[\"Time\",\"BUN\",\"Glucose\",\"NEFA\",\"Insulin\",'Total VFA']], whole[\"is_eating\"], test_size=0.3)\n",
    "clf = svm.SVC(kernel = \"linear\")\n",
    "# Train classifier and predict\n",
    "clf.fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, clf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.94444444444444%\n"
     ]
    }
   ],
   "source": [
    "##Random Forest Classification\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(X_train,y_train)\n",
    "rf_predictions = rf.predict(X_test)\n",
    "print(\"Accuracy: {}%\".format(rf.score(X_test,y_test) * 100 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifications are slightly better, particularly the random forest, but ultimately we're still missing something here.  It's possible that we should be using more inputs (there's a lot more data on fatty acids and milk profile that we haven't used yet, for example), and we certainly need to optimize our parameters.  In the future, we'll also consider using different ML models, and eventually stacking our models.  We're also thinking about simplifying our models and considering solely Time, Sequence, and Treatment as inputs, using dummy variables for the categorical variables Sequence and Treatment.  We have a lot more options to consider, so all hope is not lost yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ADDING LATER\n",
    "try_this = whole[[\"Time\",\"Sequence\",\"Treatment\",\"kg_consumed\"]]\n",
    "##trying something\n",
    "seq1 = pd.get_dummies(try_this.Sequence)\n",
    "treat1 = pd.get_dummies(try_this.Treatment)\n",
    "plop = pd.concat([try_this[[\"Time\",\"kg_consumed\"]],seq1,treat1],axis=1)\n",
    "plop.head(10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(plop.drop('kg_consumed', axis=1), plop[\"kg_consumed\"], test_size=0.3)\n",
    "\n",
    "lasso = Lasso(alpha=0)\n",
    "lasso.fit(X_train, y_train)\n",
    "    \n",
    "\"\"\"print(lasso.score(X_test, y_test))\n",
    "\n",
    "randomf = RandomForestRegressor(n_estimators = 1000)\n",
    "\n",
    "randomf.fit(X_train,y_train)\n",
    "print(randomf.score(X_test,y_test))\"\"\"\n",
    "\n",
    "####################END Try\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

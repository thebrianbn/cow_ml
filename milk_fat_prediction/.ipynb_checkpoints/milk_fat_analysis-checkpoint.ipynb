{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dataset 1\n",
    "data = pd.read_excel(\"dataset_1.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "From the initial viewing of the data, we noticed that many instances had missing data for some dates (usually tdate10 through tdate12). For now, we have set those values to NaN. For the non-date values, we imputed values as the column's average.\n",
    "\n",
    "We also noticed whitespace occurred in the columns. We erased them and lowercased the names for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of an instance without data for each date, shows column formatting as well\n",
    "#data.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove whitespace from column names\n",
    "data.columns = list(map(lambda x: x.strip().lower(), data.columns))\n",
    "\n",
    "# Find values of '  .' and set to NaN, or impute mean\n",
    "for col in data.columns:\n",
    "    try:\n",
    "        data[col][data[col] == '  .'] = np.nan\n",
    "        data[col][data[col] == ' . '] = np.nan\n",
    "        data[col][data[col].apply(lambda x: x == '    .')] = \\\n",
    "            (data[col][data[col].apply(lambda x: x != '    .')]).mean()\n",
    "        if \"date\" not in col:\n",
    "            data[col] = data[col].astype(float)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Remove rows with missing rhap and rhaf values\n",
    "data = data[~data.rhap.apply(lambda x: x == '   .')]\n",
    "data = data[~data.rhaf.apply(lambda x: x == '   .')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7868, 59)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions of data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>herd</th>\n",
       "      <th># ptas</th>\n",
       "      <th>ptam</th>\n",
       "      <th>ptaf</th>\n",
       "      <th>ptap</th>\n",
       "      <th>rha # cows</th>\n",
       "      <th>% w ptas</th>\n",
       "      <th>rham</th>\n",
       "      <th>milk1</th>\n",
       "      <th>...</th>\n",
       "      <th>pro9</th>\n",
       "      <th>milk10</th>\n",
       "      <th>fat10</th>\n",
       "      <th>pro10</th>\n",
       "      <th>milk11</th>\n",
       "      <th>fat11</th>\n",
       "      <th>pro11</th>\n",
       "      <th>milk12</th>\n",
       "      <th>fat12</th>\n",
       "      <th>pro12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7868.000000</td>\n",
       "      <td>7868.000000</td>\n",
       "      <td>7868.000000</td>\n",
       "      <td>7868.000000</td>\n",
       "      <td>7868.000000</td>\n",
       "      <td>7868.000000</td>\n",
       "      <td>7868.000000</td>\n",
       "      <td>7868.000000</td>\n",
       "      <td>7868.000000</td>\n",
       "      <td>7868.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6377.000000</td>\n",
       "      <td>5862.000000</td>\n",
       "      <td>5862.000000</td>\n",
       "      <td>5862.000000</td>\n",
       "      <td>5084.000000</td>\n",
       "      <td>5084.000000</td>\n",
       "      <td>5084.000000</td>\n",
       "      <td>3792.000000</td>\n",
       "      <td>3792.000000</td>\n",
       "      <td>3792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.645018</td>\n",
       "      <td>3948.971022</td>\n",
       "      <td>142.494026</td>\n",
       "      <td>151.996187</td>\n",
       "      <td>9.072572</td>\n",
       "      <td>5.805923</td>\n",
       "      <td>214.635613</td>\n",
       "      <td>62.069268</td>\n",
       "      <td>22967.245933</td>\n",
       "      <td>61.246441</td>\n",
       "      <td>...</td>\n",
       "      <td>3.150902</td>\n",
       "      <td>62.032071</td>\n",
       "      <td>3.875384</td>\n",
       "      <td>3.140873</td>\n",
       "      <td>61.739772</td>\n",
       "      <td>3.805566</td>\n",
       "      <td>3.096755</td>\n",
       "      <td>62.259757</td>\n",
       "      <td>3.779562</td>\n",
       "      <td>3.064030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.873456</td>\n",
       "      <td>2279.585578</td>\n",
       "      <td>355.704442</td>\n",
       "      <td>354.728682</td>\n",
       "      <td>12.943216</td>\n",
       "      <td>10.895686</td>\n",
       "      <td>440.014365</td>\n",
       "      <td>28.295911</td>\n",
       "      <td>4037.126645</td>\n",
       "      <td>12.274327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134823</td>\n",
       "      <td>11.677153</td>\n",
       "      <td>0.320749</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>11.787988</td>\n",
       "      <td>0.313746</td>\n",
       "      <td>0.127782</td>\n",
       "      <td>11.521145</td>\n",
       "      <td>0.301008</td>\n",
       "      <td>0.122117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2940.000000</td>\n",
       "      <td>-108.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>1976.750000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>20598.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>3947.500000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>23328.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>5921.250000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>25661.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>7919.000000</td>\n",
       "      <td>9789.000000</td>\n",
       "      <td>1234.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>9008.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>36275.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>3.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             state         herd       # ptas         ptam         ptaf  \\\n",
       "count  7868.000000  7868.000000  7868.000000  7868.000000  7868.000000   \n",
       "mean     31.645018  3948.971022   142.494026   151.996187     9.072572   \n",
       "std      11.873456  2279.585578   355.704442   354.728682    12.943216   \n",
       "min      11.000000     1.000000     1.000000 -2940.000000  -108.000000   \n",
       "25%      23.000000  1976.750000    31.000000    -1.000000     3.000000   \n",
       "50%      31.000000  3947.500000    58.000000   213.000000    11.000000   \n",
       "75%      41.000000  5921.250000   117.000000   371.000000    17.000000   \n",
       "max      74.000000  7919.000000  9789.000000  1234.000000    63.000000   \n",
       "\n",
       "              ptap   rha # cows     % w ptas          rham        milk1  \\\n",
       "count  7868.000000  7868.000000  7868.000000   7868.000000  7868.000000   \n",
       "mean      5.805923   214.635613    62.069268  22967.245933    61.246441   \n",
       "std      10.895686   440.014365    28.295911   4037.126645    12.274327   \n",
       "min     -99.000000     2.000000     0.000000    462.000000     2.000000   \n",
       "25%       1.000000    60.000000    45.000000  20598.000000    54.000000   \n",
       "50%       7.000000    94.000000    71.000000  23328.000000    62.000000   \n",
       "75%      12.000000   186.000000    84.000000  25661.000000    70.000000   \n",
       "max      44.000000  9008.000000   250.000000  36275.000000   129.000000   \n",
       "\n",
       "          ...              pro9       milk10        fat10        pro10  \\\n",
       "count     ...       6377.000000  5862.000000  5862.000000  5862.000000   \n",
       "mean      ...          3.150902    62.032071     3.875384     3.140873   \n",
       "std       ...          0.134823    11.677153     0.320749     0.137300   \n",
       "min       ...          2.500000    15.000000     2.200000     2.500000   \n",
       "25%       ...          3.100000    55.000000     3.700000     3.100000   \n",
       "50%       ...          3.100000    63.000000     3.900000     3.100000   \n",
       "75%       ...          3.200000    70.000000     4.100000     3.200000   \n",
       "max       ...          3.700000   100.000000     6.600000     3.800000   \n",
       "\n",
       "            milk11        fat11        pro11       milk12        fat12  \\\n",
       "count  5084.000000  5084.000000  5084.000000  3792.000000  3792.000000   \n",
       "mean     61.739772     3.805566     3.096755    62.259757     3.779562   \n",
       "std      11.787988     0.313746     0.127782    11.521145     0.301008   \n",
       "min      17.000000     2.400000     2.500000    15.000000     2.400000   \n",
       "25%      54.000000     3.600000     3.000000    55.000000     3.600000   \n",
       "50%      62.000000     3.800000     3.100000    63.000000     3.800000   \n",
       "75%      70.000000     4.000000     3.200000    70.000000     3.900000   \n",
       "max     102.000000     6.200000     3.700000   100.000000     5.900000   \n",
       "\n",
       "             pro12  \n",
       "count  3792.000000  \n",
       "mean      3.064030  \n",
       "std       0.122117  \n",
       "min       2.500000  \n",
       "25%       3.000000  \n",
       "50%       3.100000  \n",
       "75%       3.100000  \n",
       "max       3.700000  \n",
       "\n",
       "[8 rows x 45 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial summary statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amount of unique states the herds are from\n",
    "len(data.state.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7868"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amount of unique herds, since each row is a unique herd, should be the same amount - removed rows\n",
    "len(data.herd.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each herd had 6-12 observations of herd production taken at various dates in the past year. In evaluating these entries, we noticed several herds had very little variation in their total milk production over the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cowMilkList = [col for col in data if col.startswith('milk')]\n",
    "cowMilk = data[cowMilkList]\n",
    "for i in range(3):\n",
    "    plt.scatter(range(1,13),cowMilk.iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We wanted to investigate if the difference in production month-to-month was worth looking into, so for each output variable of milk, fat, and protein, we found the standard deviation of that variable *for each herd individually*, then took the average of the standard deviations for each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21460056115809667\n",
      "0.16108592713282582\n",
      "1.7480361062898773\n"
     ]
    }
   ],
   "source": [
    "cowFatList = [col for col in data if col.startswith('fat')]\n",
    "cowProList = [col for col in data if col.startswith('pro')]\n",
    "cowMilkList = [col for col in data if col.startswith('milk')]\n",
    "\n",
    "cowFat = data[cowFatList]\n",
    "cowPro = data[cowProList]\n",
    "cowMilk = data[cowMilkList]\n",
    "\n",
    "sds = 0\n",
    "count = 0\n",
    "for lst in [cowFat,cowPro,cowMilk]:\n",
    "    for i in range(lst.shape[0]):\n",
    "        x = pd.Series(lst.iloc[[i]].values.tolist()[0]).describe()[2]\n",
    "        add = 0 if np.isnan(x) else 1\n",
    "        x = 0 if np.isnan(x) else x\n",
    "        count += add\n",
    "        sds += x\n",
    "    print(sds/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the average standard deviation of each output variable was very low, especially in comparison to the actual raw values we see, so we decided that the month-to-moth difference in production was insignificant enough to be ignored, and as such could just take each herd's average as our expected output variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions for automation between subjects\n",
    "\n",
    "def prepare_data(data, subject):\n",
    "    subject_columns = []\n",
    "    \n",
    "    # For each column, test if the column pertains to the subject\n",
    "    for col in data.columns:\n",
    "        if subject in col:\n",
    "            subject_columns.append(col)\n",
    "\n",
    "    # Return the average along the row of all of the subject columns\n",
    "    return data.loc[:, subject_columns].mean(axis=1, skipna=True)\n",
    "\n",
    "def split_data(X, y, test_size=0.3):\n",
    "    \n",
    "    # Remove rows where the truth label is NA\n",
    "    X_temp = X[~y.isna()]\n",
    "    y_temp = y[~y.isna()]\n",
    "    \n",
    "    # Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=test_size)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare relevant columns\n",
    "subjects = [\"milk\", \"fat\", \"pro\"]\n",
    "feature_cols = ['# ptas', 'ptam', 'ptaf', 'ptap', 'rha # cows',\n",
    "                '% w ptas', 'rham', 'rhaf', 'rhap']\n",
    "\n",
    "# Dictionaries for each subject\n",
    "y = {}\n",
    "subject_splits = {}\n",
    "cv_scores = {}\n",
    "test_rr = {}\n",
    "\n",
    "# Training feature vectors\n",
    "X = data.loc[:, feature_cols]\n",
    "\n",
    "# Split data into train and test for each subject\n",
    "for subject in subjects:\n",
    "    y[subject] = prepare_data(data, subject)\n",
    "    subject_splits[subject] = split_data(X, y[subject])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform cross-validation to test values of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    # Keep track of cv scores for the current subject\n",
    "    temp_scores = {}\n",
    "    \n",
    "    # For each alpha value, perform cross validation w/ Lasso and keep track of scores\n",
    "    for a in range(0, 25):\n",
    "        X_train, _, y_train, _ = subject_splits[subject]\n",
    "        lasso = Lasso(alpha=a)\n",
    "        temp_scores[a] = cross_val_score(lasso, X_train, y_train, cv=10).mean()\n",
    "        \n",
    "    # Store all scores in dictionary\n",
    "    cv_scores[subject] = temp_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, variations in alpha don't cause much difference in R^2 values for milk. For fat and protein, as alpha increase, our training accuracy decreases significantly. This is due to the over-complexity of the models for those large regularization values. Therefore, we will elect to have a less complex model with alpha = 0 (no regularization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'milk': 0.9894988337398536,\n",
       " 'fat': 0.9415880148701556,\n",
       " 'pro': 0.9379685441893085}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each subject, fit on train and predict on test\n",
    "for subject in subjects:\n",
    "    lasso = Lasso(alpha=0)\n",
    "    X_train, X_test, y_train, y_test = subject_splits[subject]\n",
    "    lasso.fit(X_train, y_train)\n",
    "    \n",
    "    # Store R^2 values in dictionary\n",
    "    test_rr[subject] = lasso.score(X_test, y_test)\n",
    "\n",
    "test_rr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test evaluation metrics seem really good. But we are still skeptical of the results. In future work, we will analyze the feature importances to determine what is playing the biggest role in the predictions. We may also normalize the data depending on this analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

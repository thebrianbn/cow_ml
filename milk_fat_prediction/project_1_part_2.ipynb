{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from math import sqrt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"18EA1-5 database cleaned HO only-version2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cow</th>\n",
       "      <th>Farm</th>\n",
       "      <th>System</th>\n",
       "      <th>Parity</th>\n",
       "      <th>ParityCategory</th>\n",
       "      <th>BCS</th>\n",
       "      <th>DIM</th>\n",
       "      <th>DIC</th>\n",
       "      <th>Pregnant</th>\n",
       "      <th>FatPEBV</th>\n",
       "      <th>...</th>\n",
       "      <th>10,12/preformed</th>\n",
       "      <th>20:2n6/preformed</th>\n",
       "      <th>22/preformed</th>\n",
       "      <th>20:3n6/preformed</th>\n",
       "      <th>20:4n6/preformed</th>\n",
       "      <th>20:5n3/preformed</th>\n",
       "      <th>MFD</th>\n",
       "      <th>(C13 - C11)/OBC</th>\n",
       "      <th>(C14 - C12)/DN</th>\n",
       "      <th>Trans as % of preformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>CM</td>\n",
       "      <td>5</td>\n",
       "      <td>3plus</td>\n",
       "      <td>3.250</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>No</td>\n",
       "      <td>0.017162</td>\n",
       "      <td>0.305421</td>\n",
       "      <td>0.075902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>CM</td>\n",
       "      <td>5</td>\n",
       "      <td>3plus</td>\n",
       "      <td>2.750</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>0.070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.022726</td>\n",
       "      <td>0.281875</td>\n",
       "      <td>0.197800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>405</td>\n",
       "      <td>1</td>\n",
       "      <td>CM</td>\n",
       "      <td>5</td>\n",
       "      <td>3plus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>No</td>\n",
       "      <td>0.010826</td>\n",
       "      <td>0.240153</td>\n",
       "      <td>0.084820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "      <td>CM</td>\n",
       "      <td>4</td>\n",
       "      <td>3plus</td>\n",
       "      <td>2.750</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.004562</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.013623</td>\n",
       "      <td>0.296892</td>\n",
       "      <td>0.105783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423</td>\n",
       "      <td>1</td>\n",
       "      <td>CM</td>\n",
       "      <td>5</td>\n",
       "      <td>3plus</td>\n",
       "      <td>2.875</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.297311</td>\n",
       "      <td>0.098821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cow  Farm System  Parity ParityCategory    BCS    DIM  DIC Pregnant  \\\n",
       "0   43     1     CM       5          3plus  3.250  200.0    0        N   \n",
       "1   51     1     CM       5          3plus  2.750   72.0    0        U   \n",
       "2  405     1     CM       5          3plus    NaN  212.0    0        N   \n",
       "3  408     1     CM       4          3plus  2.750  211.0    0        U   \n",
       "4  423     1     CM       5          3plus  2.875  228.0    0        N   \n",
       "\n",
       "   FatPEBV           ...             10,12/preformed  20:2n6/preformed  \\\n",
       "0   -0.200           ...                     0.00000          0.000726   \n",
       "1    0.070           ...                     0.00162          0.000000   \n",
       "2      NaN           ...                     0.00000          0.001104   \n",
       "3   -0.070           ...                     0.00000          0.001005   \n",
       "4   -0.215           ...                     0.00000          0.000849   \n",
       "\n",
       "   22/preformed  20:3n6/preformed  20:4n6/preformed  20:5n3/preformed  MFD  \\\n",
       "0      0.000663          0.004169          0.003576          0.000746   No   \n",
       "1      0.000624          0.001575          0.002038          0.000000  Yes   \n",
       "2      0.001000          0.003100          0.004451          0.000705   No   \n",
       "3      0.000442          0.002461          0.004562          0.000727  Yes   \n",
       "4      0.000583          0.003857          0.003656          0.000480  Yes   \n",
       "\n",
       "   (C13 - C11)/OBC  (C14 - C12)/DN  Trans as % of preformed  \n",
       "0         0.017162        0.305421                 0.075902  \n",
       "1         0.022726        0.281875                 0.197800  \n",
       "2         0.010826        0.240153                 0.084820  \n",
       "3         0.013623        0.296892                 0.105783  \n",
       "4         0.011611        0.297311                 0.098821  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null values in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_summary = data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C20:2n6 and BCS have too many null values. These are features that seem like they would be important in determining our target values. Imputing for these instances would not be smart, as it could have negative effects on our model. We will choose to remove these two features instead, in order to preserve more data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first add the categorical variables and retrain our models accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_summary = data.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "targets = [\"AvgMilk\", \"Fat%\", \"FatY\", \"Pro%\", \"ProY\"]\n",
    "questionable_features = [\"ECM\", \"0.4 FCM\", \"SCCS\"]\n",
    "null_columns = list(null_summary.index[:12])\n",
    "\n",
    "\n",
    "filtered_data = data.select_dtypes(include=\"float\")\n",
    "numerical_features = filtered_data.columns\n",
    "categorical_features = data.columns.difference(filtered_data.columns)\n",
    "\n",
    "# drop targets, questionable_features, and features with too many nulls, then drop rows with null values\n",
    "X = data.drop(targets + null_columns + questionable_features, axis=1).dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace categorical features with dummy columns\n",
    "for cat in categorical_features:\n",
    "    dummies = pd.get_dummies(X[cat]).rename(columns=lambda x: cat + '_' + str(x))\n",
    "    X = pd.concat([X, dummies], axis=1)\n",
    "    X = X.drop([cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop([\"Parity\",\"Cow\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset y with rows of X, and drop target rows with null values\n",
    "y = data.loc[X.index, targets].dropna()\n",
    "\n",
    "# subset X for only available rows of y\n",
    "X = X.loc[y.index, :]\n",
    "\n",
    "num_feat = numerical_features.difference(targets)\n",
    "num_feat = num_feat.difference(questionable_features)\n",
    "num_feat = num_feat.difference(null_columns)\n",
    "# normalize feature vectors only over numerical features\n",
    "X[np.array(num_feat)] = X[num_feat].apply(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "X = X.reset_index()\n",
    "X = X.drop(\"index\",axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Farm</th>\n",
       "      <th>System</th>\n",
       "      <th>ParityCategory</th>\n",
       "      <th>DIM</th>\n",
       "      <th>DIC</th>\n",
       "      <th>Pregnant</th>\n",
       "      <th>DN</th>\n",
       "      <th>OBC</th>\n",
       "      <th>16C</th>\n",
       "      <th>18C</th>\n",
       "      <th>...</th>\n",
       "      <th>10,12/preformed</th>\n",
       "      <th>20:2n6/preformed</th>\n",
       "      <th>22/preformed</th>\n",
       "      <th>20:3n6/preformed</th>\n",
       "      <th>20:4n6/preformed</th>\n",
       "      <th>20:5n3/preformed</th>\n",
       "      <th>MFD</th>\n",
       "      <th>(C13 - C11)/OBC</th>\n",
       "      <th>(C14 - C12)/DN</th>\n",
       "      <th>Trans as % of preformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CM</td>\n",
       "      <td>3plus</td>\n",
       "      <td>0.258965</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>-0.574733</td>\n",
       "      <td>-1.626048</td>\n",
       "      <td>0.098354</td>\n",
       "      <td>0.464811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287626</td>\n",
       "      <td>0.644660</td>\n",
       "      <td>-1.328113</td>\n",
       "      <td>0.680696</td>\n",
       "      <td>-0.744054</td>\n",
       "      <td>0.183113</td>\n",
       "      <td>No</td>\n",
       "      <td>1.660103</td>\n",
       "      <td>1.060692</td>\n",
       "      <td>-0.412577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CM</td>\n",
       "      <td>3plus</td>\n",
       "      <td>-1.094116</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>-1.513597</td>\n",
       "      <td>-0.462016</td>\n",
       "      <td>-1.327251</td>\n",
       "      <td>2.358164</td>\n",
       "      <td>...</td>\n",
       "      <td>6.626223</td>\n",
       "      <td>-0.859004</td>\n",
       "      <td>-1.484332</td>\n",
       "      <td>-1.898332</td>\n",
       "      <td>-2.151314</td>\n",
       "      <td>-1.405455</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.535034</td>\n",
       "      <td>0.391109</td>\n",
       "      <td>4.819629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>CM</td>\n",
       "      <td>3plus</td>\n",
       "      <td>0.385816</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>-1.236087</td>\n",
       "      <td>0.377621</td>\n",
       "      <td>-1.667484</td>\n",
       "      <td>2.298997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287626</td>\n",
       "      <td>1.426665</td>\n",
       "      <td>0.051436</td>\n",
       "      <td>-0.381637</td>\n",
       "      <td>0.056770</td>\n",
       "      <td>0.097435</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.474950</td>\n",
       "      <td>-0.795354</td>\n",
       "      <td>-0.029766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CM</td>\n",
       "      <td>3plus</td>\n",
       "      <td>0.375245</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>-0.577326</td>\n",
       "      <td>1.565306</td>\n",
       "      <td>0.860363</td>\n",
       "      <td>-0.155425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287626</td>\n",
       "      <td>1.220311</td>\n",
       "      <td>-2.229199</td>\n",
       "      <td>-1.017587</td>\n",
       "      <td>0.158302</td>\n",
       "      <td>0.142689</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.467611</td>\n",
       "      <td>0.818176</td>\n",
       "      <td>0.870006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CM</td>\n",
       "      <td>3plus</td>\n",
       "      <td>0.554951</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>-0.997481</td>\n",
       "      <td>-0.391849</td>\n",
       "      <td>-0.264374</td>\n",
       "      <td>1.221744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287626</td>\n",
       "      <td>0.898513</td>\n",
       "      <td>-1.651709</td>\n",
       "      <td>0.370336</td>\n",
       "      <td>-0.670789</td>\n",
       "      <td>-0.382518</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.210348</td>\n",
       "      <td>0.830068</td>\n",
       "      <td>0.571180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Farm System ParityCategory       DIM  DIC Pregnant        DN       OBC  \\\n",
       "0     1     CM          3plus  0.258965    0        N -0.574733 -1.626048   \n",
       "1     1     CM          3plus -1.094116    0        U -1.513597 -0.462016   \n",
       "2     1     CM          3plus  0.385816    0        N -1.236087  0.377621   \n",
       "3     1     CM          3plus  0.375245    0        U -0.577326  1.565306   \n",
       "4     1     CM          3plus  0.554951    0        N -0.997481 -0.391849   \n",
       "\n",
       "        16C       18C           ...             10,12/preformed  \\\n",
       "0  0.098354  0.464811           ...                   -0.287626   \n",
       "1 -1.327251  2.358164           ...                    6.626223   \n",
       "2 -1.667484  2.298997           ...                   -0.287626   \n",
       "3  0.860363 -0.155425           ...                   -0.287626   \n",
       "4 -0.264374  1.221744           ...                   -0.287626   \n",
       "\n",
       "   20:2n6/preformed  22/preformed  20:3n6/preformed  20:4n6/preformed  \\\n",
       "0          0.644660     -1.328113          0.680696         -0.744054   \n",
       "1         -0.859004     -1.484332         -1.898332         -2.151314   \n",
       "2          1.426665      0.051436         -0.381637          0.056770   \n",
       "3          1.220311     -2.229199         -1.017587          0.158302   \n",
       "4          0.898513     -1.651709          0.370336         -0.670789   \n",
       "\n",
       "   20:5n3/preformed  MFD  (C13 - C11)/OBC  (C14 - C12)/DN  \\\n",
       "0          0.183113   No         1.660103        1.060692   \n",
       "1         -1.405455  Yes         3.535034        0.391109   \n",
       "2          0.097435   No        -0.474950       -0.795354   \n",
       "3          0.142689  Yes         0.467611        0.818176   \n",
       "4         -0.382518  Yes        -0.210348        0.830068   \n",
       "\n",
       "   Trans as % of preformed  \n",
       "0                -0.412577  \n",
       "1                 4.819629  \n",
       "2                -0.029766  \n",
       "3                 0.870006  \n",
       "4                 0.571180  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Models with Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_target_scores_cat = {}\n",
    "rf_target_scores_cat = {}\n",
    "targets = [\"AvgMilk\", \"Fat%\", \"FatY\", \"Pro%\", \"ProY\"]\n",
    "for target in targets:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y[target],test_size=.2)\n",
    "\n",
    "    lasso = Lasso(alpha=0)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    lasso_target_scores_cat[target] = lasso.score(X_test, y_test)\n",
    "    \n",
    "for target in targets:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y[target],test_size=.2)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_target_scores_cat[target] = rf.score(X_test, y_test)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso with Categorical Features\n",
      "{'AvgMilk': 0.8103807433048387, 'Fat%': 0.7165111121776115, 'FatY': 0.9999669315529083, 'Pro%': 0.5723596068205302, 'ProY': 0.7549960946056153}\n",
      "\n",
      "Random Forest with Categorical Features\n",
      "{'AvgMilk': 0.7590614856249595, 'Fat%': 0.5956089294476881, 'FatY': 0.9920188271307946, 'Pro%': 0.5409855911000264, 'ProY': 0.758458224141088}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso with Categorical Features\")\n",
    "print(lasso_target_scores_cat, end=\"\\n\\n\")\n",
    "print(\"Random Forest with Categorical Features\")\n",
    "print(rf_target_scores_cat, end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(49, 0.765218982865557), (48, 0.7650026261948787), (89, 0.764576039475415), (90, 0.7638682222304763), (50, 0.7636973454711222)]\n"
     ]
    }
   ],
   "source": [
    "pca_all = {}\n",
    "for n in range(1,100):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X,y[target])\n",
    "    new_X = pd.DataFrame(pca.transform(X))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_X, y[target],test_size=.2)\n",
    "    lasso = Lasso(alpha=0)\n",
    "    lasso.fit(X_train,y_train)\n",
    "    pca_all[n] = np.mean(cross_val_score(lasso, new_X, y[target], cv=5))\n",
    "\n",
    "sorted_all = sorted(pca_all.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(sorted_all[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1575, 101)\n"
     ]
    }
   ],
   "source": [
    "usable = [\"DIM\",\"DIC\",\"AvgRum\",\"Farm_1\",\"Farm_2\",\"Farm_3\",\"Farm_4\",\"Farm_5\",\"MFD_No\",\"MFD_Yes\",\"ParityCategory_1\",\"ParityCategory_2\",\"ParityCategory_3plus\",\"Pregnant_N\",\"Pregnant_P\",\"Pregnant_U\",\"System_CM\",\"System_SCR\"]\n",
    "X_usable = X[usable]\n",
    "X_needs_PCA = X.drop(usable,axis=1)\n",
    "X_usable = X_usable.reset_index()\n",
    "\n",
    "print(X_needs_PCA.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Hyper parameters for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_scores = {}\n",
    "targets = [\"AvgMilk\"]\n",
    "for target in targets:\n",
    "    for n in range(1,100):\n",
    "        pca = PCA(n_components=n)\n",
    "        pca.fit(X_needs_PCA,y[target])\n",
    "        new_X = pd.DataFrame(pca.transform(X_needs_PCA))\n",
    "        new_X = X_usable.join(new_X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(new_X, y[target],test_size=.2)\n",
    "        lasso = Lasso(alpha=0)\n",
    "        lasso.fit(X_train,y_train)\n",
    "        optimized_scores[n] = np.mean(cross_val_score(lasso, new_X, y[target], cv=5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(78, 0.7564194016317944), (76, 0.7563910220326788), (79, 0.7562514108564395), (77, 0.755514092146855), (75, 0.7526080178411075)]\n"
     ]
    }
   ],
   "source": [
    "sorted_x = sorted(optimized_scores.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(sorted_x[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, running PCA over a subset of the dataset doesn't benefit as we thought it would, so we're going to stick with running PCA over the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter optimization for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{None: 0.6464476303243053, 10: 0.6469146312953848, 25: 0.6475005998766874, 50: 0.6515490467936693}\n"
     ]
    }
   ],
   "source": [
    "parameter_scores = {}\n",
    "for trees in [None,10,25,50]:\n",
    "    rf = RandomForestRegressor(n_estimators=100,max_depth=trees)\n",
    "    parameter_scores[trees] = np.mean(cross_val_score(rf,X,y[target],cv=5))\n",
    "\n",
    "print(parameter_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.642479369992148, 3: 0.6423609233331999, 8: 0.6371783205787537, 20: 0.6015842162819055}\n"
     ]
    }
   ],
   "source": [
    "parameter_scores = {}\n",
    "for trees in [1,3,8,20]:\n",
    "    rf = RandomForestRegressor(n_estimators=100,max_depth=50,min_samples_leaf=trees)\n",
    "    parameter_scores[trees] = np.mean(cross_val_score(rf,X,y[target],cv=5))\n",
    "print(parameter_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.645257918975101, 3: 0.6434569077656944, 8: 0.6307531255124291, 20: 0.6055800384795125}\n"
     ]
    }
   ],
   "source": [
    "parameter_scores = {}\n",
    "for trees in [1,3,8,20]:\n",
    "    rf = RandomForestRegressor(n_estimators=100,max_depth=50,min_samples_leaf=trees, bootstrap=True)\n",
    "    parameter_scores[trees] = np.mean(cross_val_score(rf,X,y[target],cv=5))\n",
    "print(parameter_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't improve our results, dumping Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Vector Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8466456005049867\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y[\"AvgMilk\"],test_size=.2)\n",
    "lasso.fit(X_train,y_train)\n",
    "print(lasso.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C11:0', 12.806152370693237), ('C10:0', 12.074778437755139), ('C17:0', 11.659892536897123), ('C10/DN', 11.639437349051468), ('C14:0', 10.62044559030371)]\n",
      "[('C12:0', -11.432765807243374), ('C13:0', -9.883991210270706), ('C6/DN', -9.543575700181627), ('C15:0', -9.517582430177475), ('C11/OBC', -8.457307750619744)]\n"
     ]
    }
   ],
   "source": [
    "coefs_dict = {}\n",
    "for i in range(len(list(X))):\n",
    "    coefs_dict[list(X)[i]] = lasso.coef_[i]\n",
    "\n",
    "sorted_x = sorted(coefs_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(sorted_x[:5])\n",
    "rev = sorted_x[-5:]\n",
    "print(rev[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most useless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('MFD_Yes', 2.4480453553024087e-16), ('System_SCR', 5.456774191999631e-16), ('16/16C', 0.00854680156442817), ('DIC', -0.0362964029756437), ('Pregnant_N', -0.04449736359112887), ('C24:1n9', -0.08065665857554456), ('C22:4n6', -0.0966336178438781), ('181c12/preformed', -0.10075920462386159), ('C18:1c11', -0.10300993384080817), ('t12/preformed', 0.16816737022544068), ('C22:5n3', -0.1841156021005176), ('iC17:0', -0.22940653553979146), ('Farm_2', -0.36526958707758533), ('t15/preformed', 0.3727164146702887), ('System_CM', 0.39118747703920975), ('C24:0', -0.40000678848073096), ('20:1/preformed', -0.49759738688674116), ('20:3n6/preformed', 0.5452427899102299), ('18:3,6,9,12/preformed', -0.5520408771774333), ('t4/preformed', -0.5521111735656695), ('Pregnant_U', -0.5821344545724386), ('ParityCategory_3plus', 0.5884025627436573), ('CLAc9t11', 0.6458787970669938), ('a15/OBC', -0.6920238820619072), ('t5/preformed', -0.779524018973016), ('MFD_No', -0.8102781435470087), ('AvgRum', 0.8290702044379678), ('14:1c9/DN', 1.0152886629219844), ('18:3,9,12,15/preformed', 1.0196717108970097), ('C18:1c12', -1.0248152353960462)]\n"
     ]
    }
   ],
   "source": [
    "useless = sorted(coefs_dict.items(), key=lambda kv: abs(kv[1]))\n",
    "print(useless[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
